## Clip Diffusion

### 簡介
- 根據 [VQGAN-CLIP](https://colab.research.google.com/drive/1go6YwMFe5MX6XM9tv-cnQiSTU50N9EeT?fbclid=IwAR30ZqxIJG0-2wDukRydFA3jU5OpLHrlC_Sg1iRXqmoTkEhaJtHdRi6H7AI)、[CLIP-Guided-Diffusion](https://github.com/afiaka87/clip-guided-diffusion) 等方式進行修改與調整
- 結合 [Disco Diffusion](https://github.com/alembics/disco-diffusion) 的進階 Cutout
- 可用 [Latent Diffusion](https://github.com/CompVis/latent-diffusion) 生成初始圖片
- 使用 [Aesthetic Predictor](https://github.com/LAION-AI/aesthetic-predictor)、[Improved Aesthetic Predictor](https://github.com/christophschuhmann/improved-aesthetic-predictor) 協助生成
- 提供自動添補關鍵字功能
- 支援中文(繁體、簡體)
- 使用 [Anvil](https://anvil.works/) 撰寫網頁前端
- 使用 [Google Colab](https://colab.research.google.com/notebooks/welcome.ipynb?hl=zh-tw) 當作伺服器(經費問題QQ)
- codebase 主要依據 [CLIP-Guided-Diffusion](https://github.com/afiaka87/clip-guided-diffusion) 進行大量修改
- 其他參考來源
  1. [CLIP Guided Diffusion HQ 512x512 Uncond.ipynb](https://colab.research.google.com/drive/1QBsaDAZv8np29FPbvjffbE1eytoJcsgA)
  2. [dalle-pytorch](https://github.com/lucidrains/DALLE-pytorch)
  3. [關鍵字資料來源](https://docs.google.com/spreadsheets/d/1j7zaDi_PkndizQ2pL8B_yMcwfKUdE6tSMhL31bYtJNs/edit#gid=0)
  4. [styles.csv及media.csv來源](https://github.com/pharmapsychotic/clip-interrogator)
- model 下載網址
  1. [building.pt](https://drive.google.com/file/d/1wpV1JrT0hPu4fXfoP8_bDApAXUFsuzTg/view?usp=share_link)
  2. [stable_landscape.pt](https://drive.google.com/file/d/1l1_RBVGLMBHNUO6x-K816vCQtPSF8HzL/view?usp=share_link)
